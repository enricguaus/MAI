# MAI
Musicians and Artificial Intelligence  
by Fèlix Pastor ([ESMUC](https://www.esmuc.cat/) | [Sheepdog](http://sheepdog.es/)) and Enric Guaus ([ESMUC](https://www.esmuc.cat/) | [Sheepdog](http://sheepdog.es/))  
SONAR+D  
Friday, June 16, 2023, 12:00-13:00.  
[Lounge+D](https://sonar.es/en/activity/lounged-viernes)

## Introduction
In the last years, Artificial Intelligence has provided numerous breakthroughs within the music industries.  Copyright management companies using AI (p.ex. [BMAT](https://www.bmat.com/), free online text to speech applications (p.ex. [Murf](https://murf.ai/)) or noise removal plugins (p.ex.. [LALAL.AI](https://www.lalal.ai/voice-cleaner/)), among others, are good examples of that. Nowadays, part of the research in music applications using AI is focused on the automatic creation of melodies given a list of tags (p.ex. Mubert), a short textual description ( p.ex. Riffusion) or a detailed textual description (p.ex. MusicML). These stunning products are the result of many years of research carried aout by universities and institutions sharing their results through research papers in journals and conferences (p.ex. ISMIR), code (p.ex. Tensorflow) and datasets (p.ex. MusicBrainz).  

However, it is well known that machine learning algorithms tend to propose models that hardly deviate from the parameters established by the data itself. This makes all of the initiatives mentioned above useless for many composers and performers. Traditionally, artists create their aesthetic models based on knowledge, tradition, social context, etc. but there is always a component of innovation, risk and customization that current AI models cannot include. Nevertheless, there are some successful examples of composers who have used AI models in their compositions in contemporary music (Carles Marigó), jazz (Marco Mezquida) or electronic music (Mouse on Mars). In these cases, the models used on stage have been created thanks to external collaboration or extensive in-house knowledge in computer science and data mining. According to Born (2021), this division of tasks between the composer and scientist may become a “subordination-service” in which science is brought in apparently as subordinate discipline to ‘serve’ what are assumed to be the pre-existing, autonomous creative ‘visions’ or ‘needs’ of composers.

## Goals
The “Musicians and Artificial Intelligence” project seeks to explore the intersection between the musical and scientific approaches to AI through a showcase of PureData and SuperCollider patches that propose the use of different architectures for creating AI models that can be mapped to a DAW or any other synthesis software via OSC or MIDI. 

## Resources

Here is a set of very simple patches

## Future work

* Convert to VST plugins for DAWs (eliminates Blackhole, MIDI and OSC configurations)
* Please, use it and send feedback!

## Lectures

* Cavall Fort
* TBO